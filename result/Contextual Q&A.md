# Experiment 3: Contextual Q&A Functionality
### **Objectives**  
To evaluate NotebookLM’s ability to provide accurate, source-based answers to user queries related to digital marketing concepts.

---

### **Method**  
Lecture content and textbook excerpts were uploaded, then questions were asked using plain English, such as:
- “Criteria for Dividing Customers into Target Groups”
- “How to Rank High in Search Engines?”
- “What is SEO?”

The goal was to verify:
- Whether responses were accurate and context-based
- If NotebookLM referenced the correct documents
- Whether the answers were concise and easy to understand

---

### **Result**

NotebookLM accurately extracted answers from uploaded lecture content. When asked about "Criteria for Dividing Customers into Target Groups" it generated an explanation that referenced both criteria and example variables that can classified.

![image](https://github.com/user-attachments/assets/bca51559-e0db-4365-b42f-69be5f577c65)

Responses were context-sensitive and mostly free of hallucinations. The assistant was particularly strong at summarising models (e.g., AIDA, STP) from course notes.

![image](https://github.com/user-attachments/assets/4190c1e3-0b01-4863-8eb7-d5a2170bf2e6)

---

### **Conclusion**  
NotebookLM’s Q&A feature functions well in an academic context, offering reliable support for concept reinforcement and exam preparation.
